<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Unabatedly Eigen</title>
    <link>/categories/research/</link>
    <description>Recent content in Research on Unabatedly Eigen</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/research/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A statistical approach to discerning adversarial attacks</title>
      <link>/blog/adversary/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/adversary/</guid>
      <description>A neural network is a computer algorithm that uses calculus to, make predictions from a given set of parameters, either as a number(linear regression) or as a class(classification). One of the most useful cases of a Neural network is in image classification. In this project we use a statistical approach to identify the differences between white box adversarial attacks, black box adversarial attacks, and random noise. An adversarial attack consists of changing the pixels of input images to change a neural networkâ€™s prediction.</description>
    </item>
    
  </channel>
</rss>